{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3 - Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A *clustering function* assigns to any metric space $(S, d)$ a partition of the underlying set $S$. (It's fine if $d$ doesn't satisfy the triangle inequality, is a similarity, etc.)\n",
    "\n",
    "One of the main types of unsupervised learning -- no labels.\n",
    "\n",
    "Applications:\n",
    "- Segment customers, transactions, patients\n",
    "- Feature selection: Cluster the feature space before applying a supervised machine learning algorithm\n",
    "- Ensemble methods: In a classification problem, cluster $S\\vert_{y=1}$ (the set with one of the labels) and train classifiers to predict each cluster separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motto: clustering is the statistical counterpart of taking path connected components of a topological space.\n",
    "### Planet Pure Math\n",
    "[a picture of connected components in the plane]\n",
    "\n",
    "Taking the path components means quotient $X$ by the equivalence relation generated by $x_0\\sim x_1$ if there is a continuous map $f:[0,1]\\to X$ where $f(0) = x_0$ and $f(1) = x_1$ (i.e. a path connecting $x_0$ and $x_1$).\n",
    "\n",
    "### Planet Data\n",
    "[a picture of data that looks like it's sampled from the prior picture]\n",
    "\n",
    "A possible clustering algorithm: quotient $X$ by the equivalence relation generated by $x_0\\sim x_1$ if $d(x_0, x_1)\\leq \\epsilon$ for a fixed $\\epsilon$. That is, $x_0$ and $x_1$ are identified if they can be connected by a path where all links are length $\\leq\\epsilon$.\n",
    "\n",
    "This is called *single linkage clustering with threshold* $\\epsilon$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we consider all $\\epsilon$ at once?\n",
    "\n",
    "*Single linkage procedure*: \n",
    "- Every point starts as its own cluster. \n",
    "- Distance between two clusters $d(c_1, c_2) = \\min_{x\\in c_1, y\\in c_2}(d(x, y))$.\n",
    "- Keep merging clusters, always choosing the pair that minimizes $d(c_i, c_j)$.\n",
    "- Stop when only one cluster remains.\n",
    "\n",
    "[picture]\n",
    "[picture of the tree, which follows the progress of this algorithm, and also shows what happens as you vary the $\\epsilon$ parameter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Axioms for Clustering (Kleinberg's Theorem)\n",
    "\n",
    "Conditions on a clustering function $f$.\n",
    "\n",
    "1. Scale invariance<br>\n",
    "The clustering algorithm should not care if I multiply all entries in the distance matrix by a positive constant. $$f(d) = f(\\alpha d), \\alpha > 0$$\n",
    "2. Consistency<br>\n",
    "Starting with a known clustering, if intra-cluster distances decrease and inter-cluster distances increase, then the clustering should remain the same.\n",
    "3. Richness (Surjectivity)<br>\n",
    "Any partition of the underlying space $S$ can be realized by some distance matrix $d$.\n",
    "\n",
    "Comment: single linkage clustering with a threshold is not scale invariant, but it can be made scale invariant by making a good choice of $\\epsilon$ depending on the distance matrix.\n",
    "\n",
    "*Kleinberg's Impossibility Theorem*: There is no clustering algorithm satisfying all three of these axioms.\n",
    "\n",
    "This theorem highlights the trade-offs you make in choosing a clustering algorithm, and maybe explains why there are so many, none of which really work all that well all the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 out of 3 is all right\n",
    "Can achieve any 2 out of 3 axioms above via different stopping conditions on single linkage procedure.\n",
    "\n",
    "*Example 1*: Do single linkage, stopping when there are exactly $k$ clusters.<br>\n",
    "This misses surjectivity.\n",
    "\n",
    "*Example 2*: Do single linkage, stopping when the minimum distance between clusters exceeds $r$ (i.e. cut the tree vertically).<br>\n",
    "This misses scale invariance.\n",
    "\n",
    "*Example 3*: Do single linkage, stopping when you've added all edges of weight $\\leq\\alpha\\max_{x_0, x_1}d(x_0, x_1)$ for some $0< \\alpha< 1$ (the \"scale-$\\alpha$\" condition).<br>\n",
    "This misses consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objections to Kleinberg\n",
    "Objection to condition 3: maybe there are uninteresting partitions we don't need to realize, such as everything in one cluster or everything in its own cluster.\n",
    "\n",
    "Objection to condition 2: [picture] demonstrating that it's possible to introduce new structure (sub-clusters / clustering on a different scale) by shrinking intra-cluster distances and increasing inter-cluster distances.\n",
    "\n",
    "Consider the following relaxations of those conditions.\n",
    "\n",
    "$2^\\prime$. Refinement consistency. Starting with a known clustering, shrinking intra-cluster distances and increasing inter-cluster distances cannot merge clusters but can further refine them.\n",
    "\n",
    "$3^\\prime$. Must be able to realize any partition except the one where every point is in its own cluster.\n",
    "\n",
    "There *is* a clustering function satisfying $1$, $2^\\prime$, and $3^\\prime$. It's obtained by an intelligent parameter choice on single-linkage clustering. I'm going to leave it as a mystery. (Threshold is multiple of minimum distance between points.)\n",
    "\n",
    "Axioms, theorem, objection are all in Kleinberg's paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A brief intro to categories and functors\n",
    "\n",
    "A *category*, generally denoted $\\mathcal{C}$, is a collection of mathematical objects and morphisms satisfying some conditions.\n",
    "\n",
    "Examples:\n",
    "1. $\\textbf{Ab}$, the category in which objects are abelian groups and morphisms are homomorphisms of groups\n",
    "2. $\\mathrm{Vect}_k$, the category in which objects are $k$-vector spaces and the morphisms are $k$-linear maps\n",
    "3. $\\textbf{Top}$, the category in which objects are topological spaces and the morphisms are continuous maps\n",
    "\n",
    "A *functor* $F:\\mathcal{C}\\to\\mathcal{D}$ (morphism of categories) is a compatible system of maps from objects of $\\mathcal{C}$ to objects of $\\mathcal{D}$, and morphisms in $\\mathcal{C}$ to morphisms in $\\mathcal{D}$, i.e., $F(\\mathcal{C}\\xrightarrow{f} \\mathcal{C}^\\prime) = F(\\mathcal{C})\\xrightarrow{{F(f)}} F(\\mathcal{C}^\\prime)$ such that $ F(f\\circ g) = F(f)\\circ F(g)$. For example, taking $H_n^{sing}(-, k)$ (degree $n$ singular homology with coefficients in a field $k$) is a functor from $\\textbf{Top}$ to $\\mathrm{Vect}_k$.\n",
    "\n",
    "\"If you have something you think might be bogus, try to find out if it's functorial.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functorial clustering algorithms\n",
    "\n",
    "This is due to Carlsson-Mémoli.\n",
    "\n",
    "Let $M^{\\mathrm{inj}}$ be the category of metric spaces with injective, distance non-increasing maps. Let $Part$ be the category of partitioned sets, where the morphisms are maps of sets compatible with the partition. Elements of the partition can be merged, but not further broken apart.\n",
    "\n",
    "Since the clustering function is now being thought of as a functor, we will promote it from $f$ to $F$.\n",
    "\n",
    "The clustering functions we've defined are maps from (the category of metric spaces) to $Part$. To be functorial would mean the following. If we have a distance non-increasing map between metric spaces $g:(S, d)\\to (S^\\prime, d^\\prime)$ and a clustering method $F: (S, d)\\to (S, \\Gamma_S)$ and $F: (S^\\prime, d^\\prime)\\to (S^\\prime, \\Gamma_{S^\\prime})$, then we have $F(g): (S, \\Gamma_S)\\to (S^\\prime, \\Gamma_{S^\\prime})$, a morphism in $Part$ (i.e., it may merge clusters but it does not split them apart).\n",
    "\n",
    "So, saying that a clustering algorithm is functorial means that clusters can be merged, but not broken apart under distance non-increasing maps.\n",
    "\n",
    "Example: Single linkage clustering with a fixed $\\epsilon$ is functorial. [some details and a picture]\n",
    "\n",
    "Another characterization of single linkage: identify two points in $X$ if they can be connected by a sequence of morphisms (in $M^{\\mathrm{inj}}$) from the path of length $\\epsilon$ (i.e, two points distance $\\epsilon$ apart) to $X$.\n",
    "\n",
    "Example: Generalize the above, replacing the path of length $\\epsilon$ with another space, e.g. a triangle whose side lengths are all $\\epsilon$. So, to put points in the same cluster, we require that we can connect them with a sequence of triangles of a certain size.\n",
    "\n",
    "Motivation for this generalization: the chaining effect / the failure of single linkage on spaces with differing densities. [picture of dumbbell] \n",
    "\n",
    "Comparison to axioms above: $M^{\\mathrm{inj}}$ only allows distances to decrease, whereas consistency (above) allows some distances to increase. On the other hand, the \"morphisms\" allowed by consistency are bijections on the underlying sets, but $M^{\\mathrm{inj}}$ allows injections as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "### Any reason to go more complicated than the triangle?\n",
    "Can handle densities even better, but not really better. It becomes computationally prohibitive.\n",
    "\n",
    "### A random comment\n",
    "The class of clustering algorithms obtained by replacing the path of length $\\epsilon$ in single linkage clustering (i.e., require points be connected by a sequence of morphisms from some model space(s)) is equivalent to clustering algorithms satisfying the property that \"the clustering algorithm doesn't break up clusters any further when you apply it to the clusters themselves\" (\"excisive\", or idempotent). More explicitly, if $F$ partitions $(S,d)$ into $\\coprod_i (S_i, d_i)$, then $F$ applied to $(S_i, d_i)$ (viewed as a metric space in its own right) does not partition $S_i$ any further.\n",
    "\n",
    "There do exist functorial clustering algorithms that cannot be described in this way (i.e., cannot be described in terms of connecting points with maps from some class of model spaces) and therefore are not excisive (i.e., may result in further decomposition when applied to an element of a partition). Example due to Carlsson-Mémoli is single linkage with parameter $1 / min_{x,y} d(x, y)$. The point is that the threshold changes when you restrict to a component (since the minimum of a subset may be higher, the threshold may decrease on restriction to a subset, hence the cluster may further decompose)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
